
# MultiSenseBadminton: Wearable Sensor–Based Biomechanical Dataset for Evaluation of Badminton Performance

### CATEGORIES

- Computer-Human Interaction
- Human Movement and Sports Science not elsewhere classified
- Applied Computer Science

### KEYWORDS

- badminton players
- Wearable sensors
- body tracking and recognition
- eyetracking technology
- EMG signals
- deep learning
- AI coaching relative
- Automated coaching

The sports industry is witnessing an increasing trend of utilizing multiple synchronized sensors to collect player data, enabling the creation of personalized training systems with real-time feedback from multiple perspectives. Badminton could benefit from these various sensors, but there is a notable lack of comprehensive badminton action datasets for analysis and training feedback. To address this gap, this paper introduces a multi-sensor-based badminton action dataset for forehand clear and backhand drive strokes. This includes 7,763 badminton swing data from 25 players. It provides eye tracking, body tracking, muscle signals, foot pressure, detailed annotation data on stroke type, skill level, hitting sound, ball landing, hitting location, survey data, and interview data. The dataset was designed based on interviews with badminton coaches to ensure usability. The dataset includes a range of skills consisting of 12 novices, 8 intermediates, and 5 experts, providing resources for understanding biomechanics across skill levels. We validate the potential usefulness of our dataset by applying a proof-of-concept machine learning model to classify stroke type and level of expertise.

This project was conducted as a component of collaborative research between GIST and MIT, and it originated from MIT's earlier research endeavor known as NeurIPS [ActionSense](https://proceedings.neurips.cc/paper_files/paper/2022/file/5985e81d65605827ac35401999aea22a-Paper-Datasets_and_Benchmarks.pdf). For the data set collection framework, preprocessing of sensor data, and network system in this study, the approach outlined in the ActionSense paper was adopted. Further details can be found on the ActionSense GitHub repository and project page. [ActionSense Project Pages](https://action-net.csail.mit.edu/), [ActionSense GitHub](https://github.com/delpreto/ActionNet)

Access to the MultiSenseBadminton Dataset: The dataset for MultiSenseBadminton is available at [https://doi.org/XXXXX](https://doi.org/10.6084/m9.figshare.c.6725706.v1). This link provides direct access to the dataset, facilitating its use for research and analysis in the field of sports biomechanics and performance evaluation.

## Sensors to use

![Sensors to use](https://user-images.githubusercontent.com/79134282/233352475-a961fe8a-ba6c-4d77-a83b-8449ddeea52e.jpg)

## Data Collection Framework

![SciData 2](https://github.com/dailyminiii/MultiSenseBadminton/assets/79134282/7a499e20-4744-4a20-ba83-f5c5a95e2aee)


## Environment

![Environment](https://user-images.githubusercontent.com/79134282/233352857-31ca2d5e-73ab-4e29-b44b-ae304c2011ab.jpg)

## Data Annotation

![Figure6-1](https://github.com/dailyminiii/MultiSenseBadminton/assets/79134282/281243d5-f841-422f-8b75-3b1dea3753da)


## Data Preprocessing

![화면 캡처 2024-03-04 111713](https://github.com/dailyminiii/MultiSenseBadminton/assets/79134282/8672aee8-c37a-4e80-86c6-f4b49ca6ffb8)



## Contact

If you have any questions regarding the dataset, please feel free to contact me at seongminwoo AT gm.gist.ac.kr









